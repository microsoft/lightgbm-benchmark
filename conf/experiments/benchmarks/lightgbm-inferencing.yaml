# This experiment runs multiple variants of lightgbm inferencing + treelite
# on a given user-defined dataset and model
#
# to execute:
# > python src/pipelines/azureml/lightgbm_inferencing.py --exp-config conf/experiments/benchmarks/lightgbm-inferencing.yaml

defaults:
  - aml: custom
  - compute: custom

### CUSTOM PARAMETERS ###

experiment:
  name: "lightgbm_inferencing_dev"
  description: "something interesting to say about this"

run:
  submit: true

lightgbm_inferencing_config:
  # name of your particular benchmark
  benchmark_name: "benchmark-inferencing-20211216.1" # need to be provided at runtime!

  # list all the data/model pairs to run inferencing with
  tasks:
    - data:
        name: "data-synthetic-regression-10cols-10000samples-inference"
      model:
        name: "model-synthetic-regression-10cols-10trees-31leaves"
    - data:
        name: "data-synthetic-regression-10cols-10000samples-inference"
      model:
        name:  "model-synthetic-regression-10cols-100trees-31leaves"
    - data:
        name: "data-synthetic-regression-10cols-10000samples-inference"
      model:
        name:  "model-synthetic-regression-10cols-1000trees-31leaves"
    - data:
        name: "data-synthetic-regression-10cols-10000samples-inference"
      model:
        name:  "model-synthetic-regression-10cols-5000trees-31leaves"
    - data:
        name: "data-synthetic-regression-100cols-10000samples-inference"
      model:
        name:  "model-synthetic-regression-100cols-10trees-31leaves"
    - data:
        name: "data-synthetic-regression-100cols-10000samples-inference"
      model:
        name:  "model-synthetic-regression-100cols-100trees-31leaves"
    - data:
        name: "data-synthetic-regression-100cols-10000samples-inference"
      model:
        name:  "model-synthetic-regression-100cols-1000trees-31leaves"
    - data:
        name: "data-synthetic-regression-100cols-10000samples-inference"
      model:
        name:  "model-synthetic-regression-100cols-5000trees-31leaves"
    - data:
        name: "data-synthetic-regression-1000cols-10000samples-inference"
      model:
        name:  "model-synthetic-regression-1000cols-10trees-31leaves"
    - data:
        name: "data-synthetic-regression-1000cols-10000samples-inference"
      model:
        name:  "model-synthetic-regression-1000cols-100trees-31leaves"
    - data:
        name: "data-synthetic-regression-1000cols-10000samples-inference"
      model:
        name:  "model-synthetic-regression-1000cols-1000trees-31leaves"
    - data:
        name: "data-synthetic-regression-1000cols-10000samples-inference"
      model:
        name:  "model-synthetic-regression-1000cols-5000trees-31leaves"

  # list all inferencing frameworks and their builds
  variants:
    - framework: lightgbm_python # v3.3.0 via pypi
    - framework: lightgbm_c_api # v3.3.0 with C API prediction
    - framework: lightgbm_c_api # v3.3.0 with C API prediction
      build: docker/lightgbm-custom/v330_patch_cpu_mpi_build.dockerfile
    - framework: lightgbm_c_api # v3.2.1 with C API prediction
      build: docker/lightgbm-v3.2.1/linux_cpu_mpi_build.dockerfile
    - framework: lightgbm_c_api # v3.2.1 with C API prediction
      build: docker/lightgbm-custom/v321_patch_cpu_mpi_build.dockerfile
    # - framework: lightgbm_ray # ray implementation
    - framework: lightgbm_ort # ONNX RT implementation
    - framework: lightgbm_ort_multithread # ONNX RT multithreaded implementation
    - framework: treelite_python # v1.3.0

    # to use custom_win_cli, you need to compile your own binaries
    # see src/scripts/inferencing/custom_win_cli/static_binaries/README.md
    #- framework: custom_win_cli
