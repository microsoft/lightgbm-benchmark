diff --git a/CMakeLists.txt b/CMakeLists.txt
index f111b7ec..e7973aac 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -274,7 +274,7 @@ if(${MM_MALLOC})
 endif()
 
 if(UNIX OR MINGW OR CYGWIN)
-    SET(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -std=c++11 -pthread -Wextra -Wall -Wno-ignored-attributes -Wno-unknown-pragmas -Wno-return-type")
+    SET(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -std=c++11 -pthread -Wextra -Wall -Wno-ignored-attributes -Wno-unknown-pragmas -Wno-return-type -mavx2")
     if(USE_DEBUG)
         SET(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -g -O0")
     else()
diff --git a/include/LightGBM/boosting.h b/include/LightGBM/boosting.h
index ddbcdbc1..f93eed35 100644
--- a/include/LightGBM/boosting.h
+++ b/include/LightGBM/boosting.h
@@ -13,6 +13,8 @@
 #include <unordered_map>
 #include <vector>
 
+#define BATCH_SIZE 4
+
 namespace LightGBM {
 
 /*! \brief forward declaration */
@@ -146,6 +148,7 @@ class LIGHTGBM_EXPORT Boosting {
   */
   virtual void Predict(const double* features, double* output,
                        const PredictionEarlyStopInstance* early_stop) const = 0;
+  virtual void PredictVector(const double* features, double* output, data_size_t count, int output_stride) const = 0;
 
   virtual void PredictByMap(const std::unordered_map<int, double>& features, double* output,
                             const PredictionEarlyStopInstance* early_stop) const = 0;
diff --git a/include/LightGBM/tree.h b/include/LightGBM/tree.h
index 4f072a64..5aa50a19 100644
--- a/include/LightGBM/tree.h
+++ b/include/LightGBM/tree.h
@@ -14,6 +14,8 @@
 #include <unordered_map>
 #include <vector>
 
+#include <immintrin.h>
+
 namespace LightGBM {
 
 #define kCategoricalMask (1)
@@ -131,6 +133,7 @@ class Tree {
   * \return Prediction result
   */
   inline double Predict(const double* feature_values) const;
+  inline void PredictVector(const double* feature_values, int num_features, double* output, int output_stride) const;
   inline double PredictByMap(const std::unordered_map<int, double>& feature_values) const;
 
   inline int PredictLeafIndex(const double* feature_values) const;
@@ -530,6 +533,8 @@ class Tree {
   std::vector<std::vector<int>> leaf_features_;
   /* \brief features used in leaf linear models; indexing is relative to used_features_ */
   std::vector<std::vector<int>> leaf_features_inner_;
+
+  std::vector<int> left_right_child_;
 };
 
 inline void Tree::Split(int leaf, int feature, int real_feature,
@@ -606,6 +611,88 @@ inline double Tree::Predict(const double* feature_values) const {
   }
 }
 
+inline void Tree::PredictVector(const double* feature_values, int num_features, double* output, int output_stride) const {
+#if 0
+  for (int i = 0; i < 4; i++) {
+    double output_value;
+    if (num_leaves_ > 1) {
+      int leaf = GetLeaf(feature_values);
+      feature_values += num_features;
+      output_value = LeafOutput(leaf);
+    } else {
+      output_value = leaf_value_[0];
+    }
+    *output += output_value;
+    output += output_stride;
+  }
+#else
+
+  const auto* split_feature_data = split_feature_.data();
+  const auto* threshold_data = threshold_.data();
+  const auto* left_right_child_data = left_right_child_.data();
+
+  int nodes[4];
+  __m128i nodev = _mm_setzero_si128();
+
+  const __m128i feature_offset = _mm_set_epi32(num_features * 3, num_features * 2, num_features * 1, num_features * 0);
+  const __m256i permutev = _mm256_set_epi32(6, 4, 2, 0, 6, 4, 2, 0);
+  const __m128i onebitsv = _mm_set1_epi32(-1);
+
+#if 1
+  for (;;) {
+    __m128i maskv = _mm_cmpgt_epi32(nodev, onebitsv);
+    __m256d maskv256 = _mm256_castsi256_pd(_mm256_cvtepi32_epi64(maskv));
+
+    if (_mm_movemask_epi8(maskv) == 0) {
+      break;
+    }
+
+    __m128i splitv = _mm_mask_i32gather_epi32(_mm_setzero_si128(), split_feature_data, nodev, maskv, sizeof(int32_t));
+    splitv = _mm_add_epi32(splitv, feature_offset);
+    __m256d featurev = _mm256_mask_i32gather_pd(_mm256_setzero_pd(), feature_values, splitv, maskv256, sizeof(double));
+
+    __m256d thresholdv = _mm256_mask_i32gather_pd(_mm256_setzero_pd(), threshold_data, nodev, maskv256, sizeof(double));
+    __m256i comparev = _mm256_castpd_si256(_mm256_cmp_pd(featurev, thresholdv, _CMP_LE_OS));
+    __m128i comparev2 = _mm256_castsi256_si128(_mm256_permutevar8x32_epi32(comparev, permutev));
+
+    __m128i left_right_index = _mm_sub_epi32(_mm_slli_epi32(nodev, 1), comparev2);
+    __m128i selectv = _mm_mask_i32gather_epi32(_mm_setzero_si128(), left_right_child_data, left_right_index, maskv, sizeof(int32_t));
+
+    nodev = _mm_blendv_epi8(nodev, selectv, maskv);
+  }
+#else
+  for (;;) {
+    __mmask8 maskk = _mm_cmpgt_epi32_mask(nodev, onebitsv);
+
+    if (_cvtmask8_u32(maskk) == 0) {
+      break;
+    }
+
+    __m128i splitv = _mm_mmask_i32gather_epi32(_mm_setzero_si128(), maskk, nodev, split_feature_data, sizeof(int32_t));
+    splitv = _mm_add_epi32(splitv, feature_offset);
+    __m256d featurev = _mm256_mmask_i32gather_pd(_mm256_setzero_pd(), maskk, splitv, feature_values, sizeof(double));
+
+    __m256d thresholdv = _mm256_mmask_i32gather_pd(_mm256_setzero_pd(), maskk, nodev, threshold_data, sizeof(double));
+//    __mmask8 comparek = _mm256_cmp_pd_mask(featurev, thresholdv, _CMP_LE_OS);
+    __m256i comparev = _mm256_castpd_si256(_mm256_cmp_pd(featurev, thresholdv, _CMP_LE_OS));
+    __m128i comparev2 = _mm256_castsi256_si128(_mm256_permutevar8x32_epi32(comparev, permutev));
+
+    __m128i left_right_index = _mm_sub_epi32(_mm_slli_epi32(nodev, 1), comparev2);
+    __m128i selectv = _mm_mmask_i32gather_epi32(_mm_setzero_si128(), maskk, left_right_index, left_right_child_data, sizeof(int32_t));
+
+    nodev = _mm_mask_blend_epi32(maskk, nodev, selectv);
+  }
+#endif
+
+  _mm_storeu_si128((__m128i*)nodes, nodev);
+
+  for (int i = 0; i < 4; i++) {
+    *output += LeafOutput(~nodes[i]);
+    output += output_stride;
+  }
+#endif
+}
+
 inline double Tree::PredictByMap(const std::unordered_map<int, double>& feature_values) const {
   if (is_linear_) {
     int leaf = (num_leaves_ > 1) ? GetLeafByMap(feature_values) : 0;
diff --git a/src/application/predictor.hpp b/src/application/predictor.hpp
index dff23add..32b51490 100644
--- a/src/application/predictor.hpp
+++ b/src/application/predictor.hpp
@@ -20,6 +20,7 @@
 #include <unordered_map>
 #include <utility>
 #include <vector>
+#include <array>
 
 namespace LightGBM {
 
@@ -65,7 +66,7 @@ class Predictor {
     predict_buf_.resize(
         OMP_NUM_THREADS(),
         std::vector<double, Common::AlignmentAllocator<double, kAlignedSize>>(
-            num_feature_, 0.0f));
+            num_feature_ * BATCH_SIZE, 0.0f));
     const int kFeatureThreshold = 100000;
     const size_t KSparseThreshold = static_cast<size_t>(0.01 * num_feature_);
     if (predict_leaf_index) {
@@ -228,24 +229,31 @@ class Predictor {
     std::function<void(data_size_t, const std::vector<std::string>&)>
         process_fun = [&parser_fun, &writer, this](
                           data_size_t, const std::vector<std::string>& lines) {
-      std::vector<std::pair<int, double>> oneline_features;
+      std::array<std::vector<std::pair<int, double>>, BATCH_SIZE> oneline_features;
       std::vector<std::string> result_to_write(lines.size());
       OMP_INIT_EX();
       #pragma omp parallel for schedule(static) firstprivate(oneline_features)
-      for (data_size_t i = 0; i < static_cast<data_size_t>(lines.size()); ++i) {
+      for (data_size_t i = 0; i < static_cast<data_size_t>(lines.size()); i += BATCH_SIZE) {
+        int tid = omp_get_thread_num();
+        data_size_t lines_this_loop = std::min<data_size_t>(static_cast<data_size_t>(lines.size()) - i, BATCH_SIZE);
         OMP_LOOP_EX_BEGIN();
-        oneline_features.clear();
-        // parser
-        parser_fun(lines[i].c_str(), &oneline_features);
-        // predict
-        std::vector<double> result(num_pred_one_row_);
-        predict_fun_(oneline_features, result.data());
-        auto str_result = Common::Join<double>(result, "\t");
+        for (data_size_t j = 0; j < lines_this_loop; j++) {
+          oneline_features[j].clear();
+          parser_fun(lines[i + j].c_str(), &oneline_features[j]);
+          CopyToPredictBuffer(predict_buf_[tid].data() + num_feature_ * j, oneline_features[j]);
+        }
+        std::vector<double> result(num_pred_one_row_ * lines_this_loop);
+        boosting_->PredictVector(predict_buf_[tid].data(), result.data(), lines_this_loop, num_pred_one_row_);
+        for (data_size_t j = 0; j < lines_this_loop; j++) {
+          ClearPredictBuffer(predict_buf_[tid].data() + num_feature_ * j,
+                             num_feature_, oneline_features[j]);
+        }
+        auto str_result = Common::Join<double>(result, "\n");
         result_to_write[i] = str_result;
         OMP_LOOP_EX_END();
       }
       OMP_THROW_EX();
-      for (data_size_t i = 0; i < static_cast<data_size_t>(result_to_write.size()); ++i) {
+      for (data_size_t i = 0; i < static_cast<data_size_t>(result_to_write.size()); i += BATCH_SIZE) {
         writer->Write(result_to_write[i].c_str(), result_to_write[i].size());
         writer->Write("\n", 1);
       }
@@ -253,7 +261,7 @@ class Predictor {
     predict_data_reader.ReadAllAndProcessParallel(process_fun);
   }
 
- private:
+ public:
   void CopyToPredictBuffer(double* pred_buf, const std::vector<std::pair<int, double>>& features) {
     for (const auto &feature : features) {
       if (feature.first < num_feature_) {
diff --git a/src/boosting/gbdt.h b/src/boosting/gbdt.h
index 472ea170..760339b4 100644
--- a/src/boosting/gbdt.h
+++ b/src/boosting/gbdt.h
@@ -237,6 +237,7 @@ class GBDT : public GBDTBase {
 
   void Predict(const double* features, double* output,
                const PredictionEarlyStopInstance* earlyStop) const override;
+  void PredictVector(const double* features, double* output, data_size_t count, int output_stride) const override;
 
   void PredictByMap(const std::unordered_map<int, double>& features, double* output,
                     const PredictionEarlyStopInstance* early_stop) const override;
diff --git a/src/boosting/gbdt_prediction.cpp b/src/boosting/gbdt_prediction.cpp
index f1f7478c..bb479d57 100644
--- a/src/boosting/gbdt_prediction.cpp
+++ b/src/boosting/gbdt_prediction.cpp
@@ -64,6 +64,44 @@ void GBDT::Predict(const double* features, double* output, const PredictionEarly
   }
 }
 
+void GBDT::PredictVector(const double* features, double* output, data_size_t count, int output_stride) const {
+  // set zero
+  std::memset(output, 0, sizeof(double) * num_tree_per_iteration_ * count);
+  const int end_iteration_for_pred = start_iteration_for_pred_ + num_iteration_for_pred_;
+  const int num_features = max_feature_idx_ + 1;
+  if (count != BATCH_SIZE) {
+    // Scalar path.
+    for (data_size_t c = 0; c < count; c++) {
+      for (int i = start_iteration_for_pred_; i < end_iteration_for_pred; ++i) {
+        // predict all the trees for one iteration
+        for (int k = 0; k < num_tree_per_iteration_; ++k) {
+          output[k + c * output_stride] += models_[i * num_tree_per_iteration_ + k]->Predict(features + c * num_features);
+        }
+      }
+    }
+  } else {
+    // Vectorized path.
+    for (int i = start_iteration_for_pred_; i < end_iteration_for_pred; ++i) {
+      // predict all the trees for one iteration
+      for (int k = 0; k < num_tree_per_iteration_; ++k) {
+        models_[i * num_tree_per_iteration_ + k]->PredictVector(features, num_features, &output[k], output_stride);
+      }
+    }
+  }
+
+  for (data_size_t c = 0; c < count; c++) {
+    if (average_output_) {
+      for (int k = 0; k < num_tree_per_iteration_; ++k) {
+        output[k] /= num_iteration_for_pred_;
+      }
+    }
+    if (objective_function_ != nullptr) {
+      objective_function_->ConvertOutput(output, output);
+    }
+    output += output_stride;
+  }
+}
+
 void GBDT::PredictByMap(const std::unordered_map<int, double>& features, double* output, const PredictionEarlyStopInstance* early_stop) const {
   PredictRawByMap(features, output, early_stop);
   if (average_output_) {
diff --git a/src/c_api.cpp b/src/c_api.cpp
index 401d2135..a088d751 100644
--- a/src/c_api.cpp
+++ b/src/c_api.cpp
@@ -18,6 +18,7 @@
 #include <LightGBM/utils/random.h>
 #include <LightGBM/utils/threading.h>
 
+#include <chrono>
 #include <string>
 #include <cstdio>
 #include <functional>
@@ -25,6 +26,7 @@
 #include <mutex>
 #include <stdexcept>
 #include <vector>
+#include <array>
 
 #include "application/predictor.hpp"
 #include <LightGBM/utils/yamc/alternate_shared_mutex.hpp>
@@ -438,14 +440,24 @@ class Booster {
       predict_contrib = true;
     }
     int64_t num_pred_in_one_row = boosting_->NumPredictOneRow(start_iteration, num_iteration, is_predict_leaf, predict_contrib);
-    auto pred_fun = predictor.GetPredictFunction();
+//    auto pred_fun = predictor.GetPredictFunction();
     OMP_INIT_EX();
     #pragma omp parallel for schedule(static)
-    for (int i = 0; i < nrow; ++i) {
+    for (int i = 0; i < nrow; i += BATCH_SIZE) {
+      int tid = omp_get_thread_num();
+      int lines_this_loop = std::min<int>(nrow - i, BATCH_SIZE);
       OMP_LOOP_EX_BEGIN();
-      auto one_row = get_row_fun(i);
+      std::array<std::vector<std::pair<int, double>>, BATCH_SIZE> batch_rows;
+      for (int j = 0; j < lines_this_loop; j++) {
+        batch_rows[j] = get_row_fun(i + j);
+        predictor.CopyToPredictBuffer(predictor.predict_buf_[tid].data() + predictor.num_feature_ * j, batch_rows[j]);
+      }
       auto pred_wrt_ptr = out_result + static_cast<size_t>(num_pred_in_one_row) * i;
-      pred_fun(one_row, pred_wrt_ptr);
+      boosting_->PredictVector(predictor.predict_buf_[tid].data(), pred_wrt_ptr, lines_this_loop, num_pred_in_one_row);
+      for (int j = 0; j < lines_this_loop; j++) {
+        predictor.ClearPredictBuffer(predictor.predict_buf_[tid].data() + predictor.num_feature_ * j,
+                                     predictor.num_feature_, batch_rows[j]);
+      }
       OMP_LOOP_EX_END();
     }
     OMP_THROW_EX();
@@ -2153,8 +2165,11 @@ int LGBM_BoosterPredictForMat(BoosterHandle handle,
   }
   Booster* ref_booster = reinterpret_cast<Booster*>(handle);
   auto get_row_fun = RowPairFunctionFromDenseMatric(data, nrow, ncol, data_type, is_row_major);
+uint64_t t0 = std::chrono::duration_cast<std::chrono::microseconds>(std::chrono::high_resolution_clock::now().time_since_epoch()).count();
   ref_booster->Predict(start_iteration, num_iteration, predict_type, nrow, ncol, get_row_fun,
                        config, out_result, out_len);
+uint64_t t1 = std::chrono::duration_cast<std::chrono::microseconds>(std::chrono::high_resolution_clock::now().time_since_epoch()).count();
+printf("!!! predict for mat %d %d, time %d\n", nrow, ncol, int(t1-t0));
   API_END();
 }
 
diff --git a/src/io/tree.cpp b/src/io/tree.cpp
index e3c77049..f43405fc 100644
--- a/src/io/tree.cpp
+++ b/src/io/tree.cpp
@@ -750,6 +750,17 @@ Tree::Tree(const char* str, size_t* used_len) {
     Log::Fatal("Tree model string format error, should contain right_child field");
   }
 
+  left_right_child_.resize(2 * (num_leaves_ - 1));
+  for (int i = 0; i < num_leaves_ - 1; i++) {
+#if 0
+    left_right_child_[i * 2] = left_child_[i];
+    left_right_child_[i * 2 + 1] = right_child_[i];
+#else
+    left_right_child_[i * 2] = right_child_[i];
+    left_right_child_[i * 2 + 1] = left_child_[i];
+#endif
+  }
+
   if (key_vals.count("split_feature")) {
     split_feature_ = CommonC::StringToArrayFast<int>(key_vals["split_feature"], num_leaves_ - 1);
   } else {
diff --git a/windows/LightGBM.vcxproj b/windows/LightGBM.vcxproj
index 59b589a4..4cb3e9c0 100644
--- a/windows/LightGBM.vcxproj
+++ b/windows/LightGBM.vcxproj
@@ -34,28 +34,28 @@
     <SccLocalPath>SAK</SccLocalPath>
     <SccProvider>SAK</SccProvider>
     <ProjectName>LightGBM</ProjectName>
-    <WindowsTargetPlatformVersion>8.1</WindowsTargetPlatformVersion>
+    <WindowsTargetPlatformVersion>10.0</WindowsTargetPlatformVersion>
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.Default.props" />
   <PropertyGroup Label="Configuration" Condition="'$(Configuration)|$(Platform)'=='Debug_mpi|x64'">
-    <PlatformToolset>v140</PlatformToolset>
+    <PlatformToolset>v142</PlatformToolset>
   </PropertyGroup>
   <PropertyGroup Label="Configuration" Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
-    <PlatformToolset>v140</PlatformToolset>
+    <PlatformToolset>v142</PlatformToolset>
   </PropertyGroup>
   <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='DLL|x64'" Label="Configuration">
-    <PlatformToolset>v140</PlatformToolset>
+    <PlatformToolset>v142</PlatformToolset>
     <ConfigurationType>DynamicLibrary</ConfigurationType>
   </PropertyGroup>
   <PropertyGroup Label="Configuration" Condition="'$(Configuration)|$(Platform)'=='Debug|x64'">
-    <PlatformToolset>v140</PlatformToolset>
+    <PlatformToolset>v142</PlatformToolset>
   </PropertyGroup>
   <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug_DLL|x64'" Label="Configuration">
-    <PlatformToolset>v140</PlatformToolset>
+    <PlatformToolset>v142</PlatformToolset>
     <ConfigurationType>DynamicLibrary</ConfigurationType>
   </PropertyGroup>
   <PropertyGroup Label="Configuration" Condition="'$(Configuration)|$(Platform)'=='Release_mpi|x64'">
-    <PlatformToolset>v140</PlatformToolset>
+    <PlatformToolset>v142</PlatformToolset>
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.props" />
   <ImportGroup Label="ExtensionSettings">
@@ -211,6 +211,7 @@
       <FunctionLevelLinking>true</FunctionLevelLinking>
       <MultiProcessorCompilation>true</MultiProcessorCompilation>
       <AdditionalIncludeDirectories>$(ProjectDir)\..\external_libs\eigen;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>
+      <EnableEnhancedInstructionSet>AdvancedVectorExtensions512</EnableEnhancedInstructionSet>
     </ClCompile>
     <Link>
       <AdditionalDependencies />
@@ -341,4 +342,4 @@
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets" />
   <ImportGroup Label="ExtensionTargets">
   </ImportGroup>
-</Project>
+</Project>
\ No newline at end of file