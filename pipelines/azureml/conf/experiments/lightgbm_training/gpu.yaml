# to execute, run from /pipelines/azureml/
# > python pipelines/lightgbm_training.py --config-dir ./conf --config-name experiments/lightgbm_training/gpu run.submit=True

defaults:
  - aml: sample
  - compute: sample
  - modules: benchmark

# run parameters are command line arguments for running your experiment
run: # params for running pipeline
  experiment_name: "lightgbm-training-dev" # IMPORTANT
  regenerate_outputs: false
  continue_on_failure: false
  verbose: false
  submit: false
  resume: false
  canary: false
  silent: false
  wait: false

module_loader: # module loading params
  use_local: "*"
  force_default_module_version: null
  force_all_module_version: null
  local_steps_folder: "../../../../../src/scripts/"

### CUSTOM PARAMETERS ###

lightgbm_training:
  benchmark_name: "benchmark-dev"

  # name of the train/test dataset pairs to train on (can provide multiple as a list)
  tasks:
    - train_dataset: "synthetic-regression-100cols-100000samples-train"
      test_dataset: "synthetic-regression-100cols-10000samples-test"

  # set of parameters to train on all tasks
  reference_training:
    # training params
    objective: "regression"
    metric: "rmse"
    boosting: "gbdt"
    tree_learner: "data"
    num_iterations: 100
    num_leaves: 31
    min_data_in_leaf: 20
    learning_rate: 0.1
    max_bin: 255
    feature_fraction: 1.0
    #register_model_as: "synthetic-regression-{num_iterations}trees-{num_leaves}leaves"

    # compute params
    #target: null
    device_type: "gpu"
    nodes: 1
    processes: 1
    override_docker: "../../../../../src/scripts/lightgbm_python/dockers/lightgbm_gpu_pip.dockerfile"
