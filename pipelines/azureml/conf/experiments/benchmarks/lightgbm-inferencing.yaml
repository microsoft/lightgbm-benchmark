# to execute, run from /pipelines/azureml/
# > python pipelines/lightgbm_inferencing.py --config-dir ./conf --config-name experiments/benchmarks/lightgbm-inferencing run.submit=True

defaults:
  - aml: sample
  - compute: sample
  - modules: benchmark

# run parameters are command line arguments for running your experiment
run: # params for running pipeline
  experiment_name: "benchmark-lightgbm-inferencing" # IMPORTANT
  regenerate_outputs: false
  continue_on_failure: false
  verbose: false
  submit: false
  resume: false
  canary: false
  silent: false
  wait: false

module_loader: # module loading params
  use_local: "*"
  force_default_module_version: null
  force_all_module_version: null
  local_steps_folder: "../../../../../src/scripts/"

### CUSTOM PARAMETERS ###

lightgbm_inferencing:
  # name of your particular benchmark
  benchmark_name: "benchmark-inferencing" # need to be provided at runtime!

  tasks:
    - inferencing_dataset: "data-synthetic-regression-10cols-10000samples-inference"
      model_dataset:  "model-synthetic-regression-10cols-10trees-31leaves"
    - inferencing_dataset: "data-synthetic-regression-10cols-10000samples-inference"
      model_dataset:  "model-synthetic-regression-10cols-100trees-31leaves"
    - inferencing_dataset: "data-synthetic-regression-10cols-10000samples-inference"
      model_dataset:  "model-synthetic-regression-10cols-1000trees-31leaves"
    - inferencing_dataset: "data-synthetic-regression-10cols-10000samples-inference"
      model_dataset:  "model-synthetic-regression-10cols-5000trees-31leaves"
    - inferencing_dataset: "data-synthetic-regression-100cols-10000samples-inference"
      model_dataset:  "model-synthetic-regression-100cols-10trees-31leaves"
    - inferencing_dataset: "data-synthetic-regression-100cols-10000samples-inference"
      model_dataset:  "model-synthetic-regression-100cols-100trees-31leaves"
    - inferencing_dataset: "data-synthetic-regression-100cols-10000samples-inference"
      model_dataset:  "model-synthetic-regression-100cols-1000trees-31leaves"
    - inferencing_dataset: "data-synthetic-regression-100cols-10000samples-inference"
      model_dataset:  "model-synthetic-regression-100cols-5000trees-31leaves"
    - inferencing_dataset: "data-synthetic-regression-1000cols-10000samples-inference"
      model_dataset:  "model-synthetic-regression-1000cols-10trees-31leaves"
    - inferencing_dataset: "data-synthetic-regression-1000cols-10000samples-inference"
      model_dataset:  "model-synthetic-regression-1000cols-100trees-31leaves"
    - inferencing_dataset: "data-synthetic-regression-1000cols-10000samples-inference"
      model_dataset:  "model-synthetic-regression-1000cols-1000trees-31leaves"
    - inferencing_dataset: "data-synthetic-regression-1000cols-10000samples-inference"
      model_dataset:  "model-synthetic-regression-1000cols-5000trees-31leaves"

  variants:
    - framework: lightgbm_python
      build: dockers/lightgbm_cpu_mpi_pip.dockerfile
      batch_size: 1
      data_loader: "numpy"
      n_threads: 1
    - framework: lightgbm_python
      build: dockers/lightgbm_cpu_mpi_build.dockerfile
      batch_size: 1
      data_loader: "numpy"
      n_threads: 1
    - framework: lightgbm_python
      build: dockers/lightgbm_cpu_mpi_custom.dockerfile
      batch_size: 1
      data_loader: "numpy"
      n_threads: 1
    - framework: treelite_python
      batch_size: 1
      data_loader: "numpy"
      n_threads: 1
